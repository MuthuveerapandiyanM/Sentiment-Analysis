{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onsv2UbmWheR"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc3IX7aLdYkl"
      },
      "outputs": [],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGy2Z7EqXEdM"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7_5dz7yYrr5"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uik6_Wc9YrfX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztvACnGnYrT_"
      },
      "outputs": [],
      "source": [
        "#NLP Libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7nXIFQQY2J4"
      },
      "outputs": [],
      "source": [
        "#Scikit Learning Libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpUhvkL6Y1-b"
      },
      "outputs": [],
      "source": [
        "#Evaluation Matrix\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "from scikitplot.metrics import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVYA6H8SZDCF"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/train.txt\", delimiter=';',names=['text','label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDNJtPBDa6YY"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC8gkdjIZC3Y"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hFtRaNPZCyC"
      },
      "outputs": [],
      "source": [
        "df_var = pd.read_csv('/content/val.txt', delimiter=';',names=['text','label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI5_btPqZCrN"
      },
      "outputs": [],
      "source": [
        "df_var.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCrlbbHoZ-MF"
      },
      "source": [
        "### Training data and Validation data are same but it seperate dataframe format\n",
        "### So Concat that datafram using pd.concat() with index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8D-sPWLZCjv"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_train, df_var])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQDV8ptpZCYv"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iW1DYLkbJ9A"
      },
      "outputs": [],
      "source": [
        "#check for the various target labels in our dataset using seaborn.\n",
        "sns.countplot(data=df, x='label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-C6pvk5cG2h"
      },
      "source": [
        "### As we can see that, we have 6 labels or targets in the dataset. We can make a multi-class classifier for Sentiment Analysis.\n",
        "### So, we will merge these labels into two classes, i.e. Positive and Negative sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxAXAn78cRuT"
      },
      "source": [
        "### 1. Positive Sentiment(1) – “joy”,”love”,”surprise”\n",
        "### 2. Negative Sentiment(0) – “anger”,”sadness”,”fear”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRLU1i0JcGOe"
      },
      "outputs": [],
      "source": [
        "#custom encoder to convert categorical target labels to numerical form, i.e. (0 and 1)\n",
        "\n",
        "def custom_encoder(df):\n",
        "    df.replace(to_replace =\"surprise\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"love\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"joy\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"fear\", value =0, inplace=True)\n",
        "    df.replace(to_replace =\"anger\", value =0, inplace=True)\n",
        "    df.replace(to_replace =\"sadness\", value =0, inplace=True)\n",
        "custom_encoder(df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEy-fbbfcfGi"
      },
      "outputs": [],
      "source": [
        "#Check the target variables\n",
        "sns.countplot(data = df, x= 'label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fWMZSrvcqZo"
      },
      "source": [
        "##### our target has changed to 0 and 1,i.e. 0 for Negative and 1 for Positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrUcbbRScs7c"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGlLXY7xc5fm"
      },
      "source": [
        "Perform some pre-processing on the data before converting it into vectors and passing it to the machine learning model.\n",
        "1\n",
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViZzkGEwcmTf"
      },
      "outputs": [],
      "source": [
        "def text_transformation(df_col):\n",
        "    corpus = []\n",
        "    lm = WordNetLemmatizer()\n",
        "    for item in df_col:\n",
        "        new_item = re.sub('[^a-zA-Z]',' ',str(item))\n",
        "        new_item = new_item.lower()\n",
        "        new_item = new_item.split()\n",
        "        new_item = [lm.lemmatize(word) for word in new_item if word not in set(stopwords.words('english'))]\n",
        "        corpus.append(' '.join(str(x) for x in new_item))\n",
        "    return corpus\n",
        "corpus = text_transformation(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9aoFKc6cmOj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "word_cloud = ''\n",
        "for row in corpus:\n",
        "    for word in row:\n",
        "        word_cloud+= ' '.join(word)\n",
        "\n",
        "wordcloud = WordCloud(width=1000,height=500,background_color='white',min_font_size=10).generate(word_cloud)\n",
        "plt.imshow(wordcloud)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7wrMg_gcmJS"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(ngram_range=(1, 2))\n",
        "traindata = cv.fit_transform(corpus)\n",
        "X = traindata\n",
        "y = df.label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdA60g80g_go"
      },
      "source": [
        "### Now comes the machine learning model creation part and in this project, I’m going to use Random Forest Classifier, and we will tune the hyperparameters using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9s-5XAUg952"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'max_features': ('auto', 'sqrt'),\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [2, 5, 10],\n",
        "    'bootstrap': [True, False]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gumUBKu7-HM1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8i-vI9g_IeQ"
      },
      "outputs": [],
      "source": [
        " GBC = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a2REuumLiqL_",
        "outputId": "8d70d77a-558f-4426-cb25-d4b0ef63d872"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 10,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 100}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search = GridSearchCV(RandomForestClassifier(),parameters,cv =2, return_train_score =True, n_jobs=-1)\n",
        "grid_search.fit(X, y)\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(432):\n",
        "    print('Parameters: ',grid_search.cv_results_['params'][i])\n",
        "    print('Mean Test Score: ',grid_search.cv_results_['mean_test_score'][i])\n",
        "    print('Rank: ',grid_search.cv_results_['rank_test_score'][i])"
      ],
      "metadata": {
        "id": "PZnZvQUPW4x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(max_features=grid_search.best_params_['max_features'],\n",
        "                                      max_depth=grid_search.best_params_['max_depth'],\n",
        "                                      n_estimators=grid_search.best_params_['n_estimators'],\n",
        "                                      min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "                                      min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
        "                                      bootstrap=grid_search.best_params_['bootstrap'])\n",
        "rfc.fit(X,y)"
      ],
      "metadata": {
        "id": "KhAToZ4OXCFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data Transformation"
      ],
      "metadata": {
        "id": "Agfx4II5XHHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test.txt',delimiter=';',names=['text','label'])\n",
        "X_test,y_test = test_df.text,test_df.label\n",
        "#encode the labels into two classes , 0 and 1\n",
        "test_df = custom_encoder(y_test)\n",
        "#pre-processing of text\n",
        "test_corpus = text_transformation(X_test)\n",
        "#convert text data into vectors\n",
        "testdata = cv.transform(test_corpus)\n",
        "#predict the target\n",
        "predictions = rfc.predict(testdata)"
      ],
      "metadata": {
        "id": "PSA7v8RRXHvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "xPOzeK4MXOJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10,5\n",
        "plot_confusion_matrix(y_test,predictions)\n",
        "acc_score = accuracy_score(y_test,predictions)\n",
        "pre_score = precision_score(y_test,predictions)\n",
        "rec_score = recall_score(y_test,predictions)\n",
        "print('Accuracy_score: ',acc_score)\n",
        "print('Precision_score: ',pre_score)\n",
        "print('Recall_score: ',rec_score)\n",
        "print(\"-\"*50)\n",
        "cr = classification_report(y_test,predictions)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "O-ZhCM_CXNwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC Curve\n",
        "\n",
        "predictions_probability = rfc.predict_proba(testdata)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,predictions_probability[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot([0,1])\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AXdvit4HXVh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Custom Input:\n",
        "\n",
        "def expression_check(prediction_input):\n",
        "    if prediction_input == 0:\n",
        "        print(\"Input statement has Negative Sentiment.\")\n",
        "    elif prediction_input == 1:\n",
        "        print(\"Input statement has Positive Sentiment.\")\n",
        "    else:\n",
        "        print(\"Invalid Statement.\")\n",
        "# function to take the input statement and perform the same transformations we did earlier\n",
        "def sentiment_predictor(input):\n",
        "    input = text_transformation(input)\n",
        "    transformed_input = cv.transform(input)\n",
        "    prediction = rfc.predict(transformed_input)\n",
        "    expression_check(prediction)\n",
        "input1 = [\"Sometimes I just want to punch someone in the face.\"]\n",
        "input2 = [\"I bought a new phone and it's so good.\"]\n",
        "sentiment_predictor(input1)\n",
        "sentiment_predictor(input2)\n",
        "\n"
      ],
      "metadata": {
        "id": "hC2Qa9HiXjou"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}